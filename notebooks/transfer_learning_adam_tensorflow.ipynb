{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sub>&copy; 2020 Neuralmagic, Inc., Confidential // [Neural Magic Evaluation License Agreement](https://neuralmagic.com/evaluation-license-agreement/)</sub> \n",
    "\n",
    "# TensorFlow Transfer Learning with Adam Optimizer\n",
    "\n",
    "This notebook provides a step-by-step walkthrough for downloading a recalibrated model from the Neural Magic Model Repo and using it for transfer learning. You will:\n",
    "- Set up the environment\n",
    "- Select a model*\n",
    "- Set up the model and dataset\n",
    "- Perform transfer learning\n",
    "- Export to [ONNX](https://onnx.ai/)\n",
    " \n",
    "\\* Models available in the Neural Magic Model Repo are called out in this notebook. You can familiarize yourself with the models from which you can transfer learn.\n",
    "\n",
    "\n",
    "Reading through this notebook will be reasonably quick to gain an intuition for what is happening. Rough time estimates for transfer learning are given. Note that training with the TensorFlow CPU implementation will be much slower than a GPU:\n",
    "- 30 minutes on a GPU\n",
    "- 3 hours on a laptop CPU\n",
    "\n",
    "## Background\n",
    "Neural networks can take a long time to train. Model optimization techniques such as [model pruning](https://towardsdatascience.com/pruning-deep-neural-network-56cae1ec5505) may be necessary to achieve both performance and optimizing goals. However, these model optimizations can involve many trials and errors due to a large number of hyperparameters. Fortunately, in the computer vision and natural language space, pruned (sparsified) neural networks [transfer learn well](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a), allowing end users to get faster time to value with their deep learning deployments without having to start from scratch.\n",
    "\n",
    "To make it easier to use pruned models, [Neural Magic](https://neuralmagic.com/) is actively:\n",
    "- Creating pruned versions of popular models and datasets\n",
    "- Thoroughly testing these models  with the Neural Magic Inference Engine to ensure performance\n",
    "- Updating the Neural Magic Repo with these models and datasets\n",
    "\n",
    "## Before you begin…\n",
    "Be sure to read through the README found in the Neural Magic ML Tooling package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Setting Up the Environment\n",
    "\n",
    "In this step, Neural Magic checks your environment setup to ensure the rest of the notebook will flow smoothly.\n",
    "Before running, install the neuralmagicML package into the system using the following at the parent of the package directory:\n",
    "\n",
    "`pip install neuralmagicML-python/ `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = \"transfer_learning_adam_tensorflow\"\n",
    "print(\"checking setup for {}...\".format(notebook_name))\n",
    "\n",
    "# filter because of tensorboard future warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    # make sure neuralmagicML is installed\n",
    "    import neuralmagicML\n",
    "except Exception as ex:\n",
    "    raise Exception(\n",
    "        \"please install neuralmagicML using the setup.py file before continuing\"\n",
    "    )\n",
    "\n",
    "from neuralmagicML.utilsnb import check_tensorflow_notebook_setup\n",
    "\n",
    "check_tensorflow_notebook_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Selecting a Model\n",
    "\n",
    "Repositories may hold many models, so a simple UI is provided to make this selection process easier. Within the UI, ﬁlters can be applied for models trained in/on speciﬁc domains or datasets. Each network architecture listed will also include options for the dataset it was trained on and the type. The type refers to how the models were trained and/or recalibrated, speciﬁcally:\n",
    "- base - baseline model, trained generally as in the original paper\n",
    "- recal - a recalibrated model that is recalibrated to the point of fully recovering the baseline model’s metrics\n",
    "- recal-perf - a recalibrated model that is recalibrated for performance to the point of recovering 99% of the baseline model’s metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicML.utilsnb import ModelSelectWidgetContainer\n",
    "\n",
    "print(\"Creating ui...\")\n",
    "container = ModelSelectWidgetContainer([\"tensorflow\"], [\"imagenet\"])\n",
    "display(container.create())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Performing Transfer Learning\n",
    "\n",
    "By default, we use the [Imagewoof](https://github.com/fastai/imagenette) dataset to transfer learn to (a dataset consisting of 10 classes of dogs). This dataset is used to show how to transfer learn on a simple dataset quickly. If you would like to try out transfer learning on your own dataset, replace the appropriate lines with your own:\n",
    "- `num_classes = 10`\n",
    "- `class_type = \"single\"`\n",
    "- `train_dataset = ...`\n",
    "- `val_dataset = ...`\n",
    "\n",
    "More information for creating and working with TensorFlow datasets can be found [here](https://www.tensorflow.org/guide/data). Take care to keep the variable names the same, as the rest of the notebook is set up according to those.\n",
    "\n",
    "The model is created in the graph based on the previous UI selections.\n",
    "\n",
    "With that setup, you will begin transfer learning from the given model onto the dataset. The library to enable this is designed to be easily plugged into nearly any training setup for TensorFlow. In the cell block below is an example of how an integration looks. The implementation here trains all layers in the selected model. If you do not wish to do that, you can disable specific layers with standard TensorFlow code. Note that only four lines are needed to be able to integrate fully.\n",
    "- Create a `ConstantKSModifier()`. This keeps the sparsity the same for any sparsiﬁed layers.\n",
    "- Create a `ScheduledModifierManager()`. This is used in combination with the `ConstantKSModifier`\n",
    "- Invoke `manager.create_ops()` for the desired graph. This updates the TensorFlow graph with the proper operators that modify the training process.\n",
    "- Use `manager.max_epochs` to know how many epochs are needed for training.\n",
    "- Invoke `sess.run(mod_ops)` on each optimizer step. This updates the modifying operators and variables in the TensorFlow graph.\n",
    "- Invoke `manager.complete_graph()` once training has completed. This wilil cleanup the graph and set any final state for graph export and saving.\n",
    "\n",
    "Once the training objects are created (optimizer, loss function, etc.), a `ScheduledModifierManager` is instantiated from the conﬁguration. Most logging and updates are done through TensorBoard for this notebook. The use of TensorBoard is entirely optional. Finally, regular training and testing code is used to go through the process.\n",
    "\n",
    "Note, for convenience a TensorBoard instance is launched in the cell below pointed at `localhost`. If you are running this notebook on a remote server, then you will need to update TensorBoard accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from tqdm import auto\n",
    "import numpy\n",
    "\n",
    "from neuralmagicML.utils import create_unique_dir, clean_path, create_dirs\n",
    "from neuralmagicML.tensorflow.models import ModelRegistry\n",
    "from neuralmagicML.tensorflow.datasets import (\n",
    "    ImagewoofDataset,\n",
    "    ImagenetteSize,\n",
    "    create_split_iterators_handle,\n",
    ")\n",
    "from neuralmagicML.tensorflow.utils import (\n",
    "    tf_compat,\n",
    "    batch_cross_entropy_loss,\n",
    "    accuracy,\n",
    "    write_simple_summary,\n",
    ")\n",
    "\n",
    "with tf_compat.Graph().as_default() as graph:\n",
    "    batch_size = 64\n",
    "    num_classes = 10\n",
    "    class_type = \"single\"\n",
    "    num_epochs = 20\n",
    "    repo_model = container.selected_model\n",
    "    model_name = repo_model.registry_key\n",
    "    input_shape = ModelRegistry.input_shape(model_name)\n",
    "    input_size = input_shape[0]\n",
    "\n",
    "    # create the datasets\n",
    "    with tf_compat.device(\"/cpu:0\"):\n",
    "        print(\"loading datasets\")\n",
    "        train_dataset = ImagewoofDataset(\n",
    "            train=True, rand_trans=True, dataset_size=ImagenetteSize.s320, image_size=input_size\n",
    "        )\n",
    "        train_len = len(train_dataset)\n",
    "        train_dataset = train_dataset.build(\n",
    "            batch_size,\n",
    "            shuffle_buffer_size=1000,\n",
    "            prefetch_buffer_size=batch_size,\n",
    "            num_parallel_calls=4,\n",
    "        )\n",
    "        train_steps = math.ceil(train_len / float(batch_size))\n",
    "\n",
    "        val_dataset = ImagewoofDataset(\n",
    "            train=False, rand_trans=False, dataset_size=ImagenetteSize.s320, image_size=input_size\n",
    "        )\n",
    "        val_len = len(val_dataset)\n",
    "        val_dataset = val_dataset.build(\n",
    "            batch_size,\n",
    "            shuffle_buffer_size=1000,\n",
    "            prefetch_buffer_size=batch_size,\n",
    "            num_parallel_calls=4,\n",
    "        )\n",
    "        val_steps = math.ceil(val_len / float(batch_size))\n",
    "\n",
    "    handle, iterator, (train_iter, val_iter) = create_split_iterators_handle(\n",
    "        [train_dataset, val_dataset]\n",
    "    )\n",
    "    images, labels = iterator.get_next()\n",
    "    training = tf_compat.placeholder(dtype=tf_compat.bool, shape=[])\n",
    "\n",
    "    # create the model and graph\n",
    "    print(\"Creating model graph for {}\".format(model_name))\n",
    "    logits = ModelRegistry.create(\n",
    "        model_name, inputs=images, training=training, num_classes=num_classes,\n",
    "    )\n",
    "\n",
    "    print(\"Creating loss, accuracy, and optimizer in graph\")\n",
    "    loss = batch_cross_entropy_loss(logits, labels)\n",
    "    acc = accuracy(logits, labels)\n",
    "    global_step = tf_compat.train.get_or_create_global_step()\n",
    "    train_op = tf_compat.train.AdamOptimizer(learning_rate=1e-4).minimize(\n",
    "        loss, global_step=global_step\n",
    "    )\n",
    "    update_ops = tf_compat.get_collection(tf_compat.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    #######################################################\n",
    "    # First lines required for transfer learning from a sparse model in TensorFlow\n",
    "    #######################################################\n",
    "    print(\"Creating constant sparse ops in graph\")\n",
    "    from neuralmagicML.tensorflow.recal import (\n",
    "        ScheduledModifierManager,\n",
    "        ConstantKSModifier,\n",
    "    )\n",
    "    manager = ScheduledModifierManager([ConstantKSModifier(params=\"__ALL__\")])\n",
    "    mod_ops, mod_extras = manager.create_ops(train_steps, global_step)\n",
    "\n",
    "    with tf_compat.Session() as sess:\n",
    "        tensorboard_path = create_unique_dir(\n",
    "            os.path.join(\".\", \"tensorboard-logs\", notebook_name, model_name)\n",
    "        )\n",
    "        print(\"logging tensorboard to {}\".format(tensorboard_path))\n",
    "        summary_writer = tf_compat.summary.FileWriter(tensorboard_path, sess.graph)\n",
    "        summaries = tf_compat.summary.merge_all()\n",
    "        \n",
    "        # startup tensorboard\n",
    "        %load_ext tensorboard\n",
    "        %tensorboard --logdir ./tensorboard-logs\n",
    "\n",
    "        print(\"initializing\")\n",
    "        sess.run(\n",
    "            [\n",
    "                tf_compat.global_variables_initializer(),\n",
    "                tf_compat.local_variables_initializer(),\n",
    "            ]\n",
    "        )\n",
    "        train_iter_handle, val_iter_handle = sess.run(\n",
    "            [train_iter.string_handle(), val_iter.string_handle()]\n",
    "        )\n",
    "\n",
    "        print(\"restoring pre-trained model weights\")\n",
    "        ModelRegistry.load_pretrained(\n",
    "            model_name, pretrained=repo_model.desc, remove_dynamic_tl_vars=True,\n",
    "        )\n",
    "\n",
    "        #######################################################\n",
    "        # Initialization line required for transfer learning from a sparse model in TensorFlow\n",
    "        # Note, initialization is called after load_pretrained to initialize from pretrained\n",
    "        #######################################################\n",
    "        manager.initialize_session()\n",
    "\n",
    "        for epoch in auto.tqdm(range(num_epochs), desc=\"transfer learning\"):\n",
    "            print(\"training for epoch {}...\".format(epoch))\n",
    "            sess.run(train_iter.initializer)\n",
    "\n",
    "            for step in range(train_steps):\n",
    "                _, __, meas_step, meas_loss, meas_acc, meas_summ = sess.run(\n",
    "                    [train_op, update_ops, global_step, loss, acc, summaries],\n",
    "                    feed_dict={handle: train_iter_handle, training: True},\n",
    "                )\n",
    "\n",
    "                if step >= train_steps - 1:\n",
    "                    # log the general summaries on the last training step\n",
    "                    summary_writer.add_summary(meas_summ, meas_step)\n",
    "\n",
    "                #######################################################\n",
    "                # Modifier update ops line for transfer learning from a sparse model in TensorFlow\n",
    "                #######################################################\n",
    "                sess.run(mod_ops)\n",
    "\n",
    "                write_simple_summary(summary_writer, \"Train/Loss\", meas_loss, meas_step)\n",
    "                write_simple_summary(\n",
    "                    summary_writer, \"Train/Acc\", meas_acc * 100.0, meas_step\n",
    "                )\n",
    "\n",
    "            print(\"validating for epoch {}...\".format(epoch))\n",
    "            sess.run(val_iter.initializer)\n",
    "            val_losses = []\n",
    "            val_acc = []\n",
    "\n",
    "            for step in range(val_steps):\n",
    "                meas_loss, meas_acc = sess.run(\n",
    "                    [loss, acc], feed_dict={handle: val_iter_handle, training: False},\n",
    "                )\n",
    "                val_losses.append(meas_loss)\n",
    "                val_acc.append(meas_acc)\n",
    "\n",
    "                write_simple_summary(\n",
    "                    summary_writer, \"Val/Loss\", numpy.mean(val_losses).item(), epoch\n",
    "                )\n",
    "                write_simple_summary(\n",
    "                    summary_writer, \"Val/Acc\", numpy.mean(val_acc).item(), epoch\n",
    "                )\n",
    "            print(\n",
    "                \"completed epoch {} with val acc {}\".format(\n",
    "                    epoch, numpy.mean(val_acc).item() * 100\n",
    "                )\n",
    "            )\n",
    "\n",
    "        #######################################################\n",
    "        # Final line for transfer learning from a sparse model in TensorFlow, complete the graph\n",
    "        #######################################################\n",
    "        manager.complete_graph()\n",
    "\n",
    "        checkpoint_path = create_unique_dir(\n",
    "            os.path.join(\".\", notebook_name, model_name, \"checkpoint\")\n",
    "        )\n",
    "        checkpoint_path = os.path.join(checkpoint_path, \"model\")\n",
    "        create_dirs(checkpoint_path)\n",
    "        saver = ModelRegistry.saver(model_name)\n",
    "        saver.save(sess, checkpoint_path)\n",
    "        print(\"saved model checkpoint to {}\".format(checkpoint_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Exporting to ONNX\n",
    "\n",
    "Now that the model is fully recalibrated, you need to export it to an ONNX format, which is the format used by the Neural Magic Inference Engine. For TensorFlow, exporting to ONNX is not natively supported. To add support, you will use the `tf2onnx` Python package. In the cell block below, a convenience class, `GraphExporter()`, is used to handle exporting. It wraps the somewhat complicated API for `tf2onnx` into an easy to use interface.\n",
    "\n",
    "Note, for some configurations, the tf2onnx code does not work properly in a Jupyter Notebook. To remedy this, you should run the `exporter.export_onnx()` function call in a Python console or script.\n",
    "\n",
    "Once the model is saved as an ONNX ﬁle, it is ready to be used for inference with Neural Magic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicML.utils import create_unique_dir, clean_path, create_dirs\n",
    "from neuralmagicML.tensorflow.utils import GraphExporter\n",
    "\n",
    "export_path = clean_path(os.path.join(\".\", notebook_name, model_name, \"exported\"))\n",
    "exporter = GraphExporter(export_path)\n",
    "\n",
    "with tf_compat.Graph().as_default() as graph:\n",
    "    print(\"Recreating graph...\", flush=True)\n",
    "\n",
    "    input_shape = ModelRegistry.input_shape(model_name)\n",
    "    images = tf_compat.placeholder(\n",
    "        tf_compat.float32, [None, input_size, input_size, 3], name=\"inputs\"\n",
    "    )\n",
    "    logits = ModelRegistry.create(\n",
    "        model_name,\n",
    "        inputs=images,\n",
    "        training=False,\n",
    "        num_classes=num_classes,\n",
    "        class_type=class_type,\n",
    "    )\n",
    "\n",
    "    input_names = [images.name]\n",
    "    output_names = [logits.name]\n",
    "\n",
    "    with tf_compat.Session() as sess:\n",
    "        sess.run(tf_compat.global_variables_initializer())\n",
    "        print(\"Restoring previous weights...\", flush=True)\n",
    "        saver = ModelRegistry.saver(model_name)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "\n",
    "        print(\"Exporting to pb...\", flush=True)\n",
    "        exporter.export_pb(outputs=[logits])\n",
    "        print(\"Exported pb file to {}\".format(exporter.pb_path), flush=True)\n",
    "\n",
    "print(\"Exporting to onnx...\", flush=True)\n",
    "exporter.export_onnx(inputs=input_names, outputs=output_names)\n",
    "print(\"Exported onnx file to {}\".format(exporter.onnx_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "Run your model (ONNX file) through the Neural Magic Inference Engine. The following is an example of code that you can run in your Python console. Be sure to enter your ONNX file path and batch size.\n",
    "\n",
    "```\n",
    "from neuralmagic import create_model\n",
    "model = create_model(onnx_file_path=’some/path/to/model.onnx’, batch_size=1)\n",
    "inp = [numpy.random.rand(1, 3, 224, 224).astype(numpy.float32)]\n",
    "out = model.forward(inp)\n",
    "print(out)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
