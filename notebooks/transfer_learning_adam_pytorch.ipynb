{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sub>&copy; 2020 Neuralmagic, Inc., Confidential // [Neural Magic Evaluation License Agreement](https://neuralmagic.com/evaluation-license-agreement/)</sub> \n",
    "\n",
    "# PyTorch Transfer Learning with Adam Optimizer\n",
    "\n",
    "This notebook provides a step-by-step walkthrough for downloading a recalibrated model from the Neural Magic Model Repo and using it for transfer learning. You will:\n",
    "- Set up the environment\n",
    "- Select a model*\n",
    "- Set up the model and dataset\n",
    "- Perform transfer learning\n",
    "- Export to [ONNX](https://onnx.ai/)\n",
    " \n",
    "\\* Models available in the Neural Magic Model Repo are called out in this notebook. You can familiarize yourself with the models from which you can transfer learn.\n",
    "\n",
    "\n",
    "Reading through this notebook will be reasonably quick to gain an intuition for what is happening. Rough time estimates for transfer learning are given. Note that training with the PyTorch CPU implementation will be much slower than a GPU:\n",
    "- 30 minutes on a GPU\n",
    "- 3 hours on a laptop CPU\n",
    "\n",
    "## Background\n",
    "Neural networks can take a long time to train. Model optimization techniques such as [model pruning](https://towardsdatascience.com/pruning-deep-neural-network-56cae1ec5505) may be necessary to achieve both performance and optimizing goals. However, these model optimizations can involve many trials and errors due to a large number of hyperparameters. Fortunately, in the computer vision and natural language space, pruned (sparsified) neural networks [transfer learn well](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a), allowing end users to get faster time to value with their deep learning deployments without having to start from scratch.\n",
    "\n",
    "To make it easier to use pruned models, [Neural Magic](https://neuralmagic.com/) is actively:\n",
    "- Creating pruned versions of popular models and datasets\n",
    "- Thoroughly testing these models  with the Neural Magic Inference Engine to ensure performance\n",
    "- Updating the Neural Magic Repo with these models and datasets\n",
    "\n",
    "## Before you begin…\n",
    "Be sure to read through the README found in the Neural Magic ML Tooling package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Setting Up the Environment\n",
    "\n",
    "In this step, Neural Magic checks your environment setup to ensure the rest of the notebook will flow smoothly.\n",
    "Before running, install the neuralmagicML package into the system using the following at the parent of the package directory:\n",
    "\n",
    "`pip install neuralmagicML-python/ `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = \"transfer_learning_adam_pytorch\"\n",
    "print(\"checking setup for {}...\".format(notebook_name))\n",
    "\n",
    "# filter because of tensorboard future warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    # make sure neuralmagicML is installed\n",
    "    import neuralmagicML\n",
    "except Exception as ex:\n",
    "    raise Exception(\n",
    "        \"please install neuralmagicML using the setup.py file before continuing\"\n",
    "    )\n",
    "    \n",
    "from neuralmagicML.utilsnb import check_pytorch_notebook_setup\n",
    "check_pytorch_notebook_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Selecting a Model\n",
    "\n",
    "Repositories may hold many models, so a simple UI is provided to make this selection process easier. Within the UI, ﬁlters can be applied for models trained in/on speciﬁc domains or datasets. Each network architecture listed will also include options for the dataset it was trained on and the type. The type refers to how the models were trained and/or recalibrated, speciﬁcally:\n",
    "- base - baseline model, trained generally as in the original paper\n",
    "- recal - a recalibrated model that is recalibrated to the point of fully recovering the baseline model’s metrics\n",
    "- recal-perf - a recalibrated model that is recalibrated for performance to the point of recovering 99% of the baseline model’s metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicML.utilsnb import ModelSelectWidgetContainer\n",
    "\n",
    "print(\"Creating ui...\")\n",
    "container = ModelSelectWidgetContainer([\"pytorch\"], [\"imagenet\"])\n",
    "display(container.create())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Dataset Setup\n",
    "\n",
    "By default, we use the [Imagewoof](https://github.com/fastai/imagenette) dataset to transfer learn to (a dataset consisting of 10 classes of dogs). This dataset is used to show how to transfer learn on a simple dataset quickly. If you would like to try out transfer learning on your own dataset, replace the appropriate lines with your own:\n",
    "- `num_classes = 10`\n",
    "- `class_type = \"single\"`\n",
    "- `train_dataset = ImagewoofDataset(dataset_root, train=True)`\n",
    "- `val_dataset = ImagewoofDataset(dataset_root, train=False)`\n",
    "\n",
    "More information for creating and working with PyTorch datasets can be found [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html). Take care to keep the variable names the same, as the rest of the notebook is set up according to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from neuralmagicML.pytorch.datasets import ImagewoofDataset, ImagenetteSize\n",
    "from neuralmagicML.pytorch.models import ModelRegistry\n",
    "from neuralmagicML.utils import clean_path\n",
    "\n",
    "#######################################################\n",
    "# Define the number of classes to transfer learn to below\n",
    "#######################################################\n",
    "num_classes = 10\n",
    "class_type = \"single\"  # use single for softmax output, multi for sigmoid output\n",
    "print(\n",
    "    \"transfer learning to {} classes and class_type {}\".format(num_classes, class_type)\n",
    ")\n",
    "\n",
    "repo_model = container.selected_model\n",
    "print(\"\\nloading model {} ...\".format(repo_model.root_path))\n",
    "model = ModelRegistry.create(\n",
    "    repo_model.registry_key,\n",
    "    pretrained=repo_model.desc,\n",
    "    num_classes=num_classes,\n",
    "    class_type=class_type,\n",
    ")\n",
    "model_name = model.__class__.__name__\n",
    "input_shape = ModelRegistry.input_shape(repo_model.registry_key)\n",
    "input_size = input_shape[-1]\n",
    "print(model)\n",
    "\n",
    "#######################################################\n",
    "# Define your train and validation datasets below\n",
    "#######################################################\n",
    "print(\"\\nloading train dataset...\")\n",
    "train_dataset = ImagewoofDataset(\n",
    "    train=True, dataset_size=ImagenetteSize.s320, image_size=input_size\n",
    ")\n",
    "print(train_dataset)\n",
    "\n",
    "print(\"\\nloading val dataset...\")\n",
    "val_dataset = ImagewoofDataset(\n",
    "    train=False, dataset_size=ImagenetteSize.s320, image_size=input_size\n",
    ")\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Performing Transfer Learning\n",
    "\n",
    "Now that the model and datasets are chosen and set up, you will begin transfer learning from the given model onto the dataset. The library to enable this is designed to be easily plugged into nearly any training setup for PyTorch. In the cell block below is an example of how an integration looks. The implementation here trains all layers in the selected model. If you do not wish to do that, you can disable specific layers with standard PyTorch code. Note that only four lines are needed to be able to integrate fully.\n",
    "- Create a `ConstantKSModifier()`. This keeps the sparsity the same for any sparsiﬁed layers.\n",
    "- Create a `ScheduledModifierManager()`. This is used in combination with the `ConstantKSModifier` and the `ScheduledOptimizer`\n",
    "- Create a `ScheduledOptimizer()`. This updates the PyTorch objects that modify the training process. It wraps the original optimizer that was used to modify the training process/graph, and should be used in place of that (`optimizer.step()` must be called on ScheduledOptimizer and not the original).\n",
    "- Call into the `ScheduledOptimizer` for `epoch_start()` and `epoch_end()` while training. These calls mark when an epoch has started and after training when an epoch has ended, respectively.\n",
    "\n",
    "Once the training objects are created (optimizer, loss function, etc.), a `ConstantKSModifier`, `ScheduledModifierManager`, and `ScheduledOptimizer` are instantiated. Almost all logging and updates are done through TensorBoard for this notebook. The use of TensorBoard is entirely optional. Finally, regular training and testing code for PyTorch is used to go through the process.\n",
    "\n",
    "Note, for convenience a TensorBoard instance is launched in the cell below pointed at `localhost`. If you are running this notebook on a remote server, then you will need to update TensorBoard accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import auto\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from neuralmagicML.pytorch.utils import (\n",
    "    CrossEntropyLossWrapper,\n",
    "    TopKAccuracy,\n",
    "    ModuleTrainer,\n",
    "    ModuleTester,\n",
    "    TensorBoardLogger,\n",
    ")\n",
    "from neuralmagicML.utils import create_unique_dir, clean_path\n",
    "\n",
    "# setup device, data loaders, loss, optimizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 128\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, pin_memory=True, num_workers=8\n",
    ")\n",
    "val_data_loader = DataLoader(\n",
    "    val_dataset, batch_size, shuffle=False, pin_memory=True, num_workers=8\n",
    ")\n",
    "loss = CrossEntropyLossWrapper(extras={\"top1acc\": TopKAccuracy(1)})\n",
    "optim = Adam(model.parameters())\n",
    "print(\"device:{} batch_size:{} loss:{}\".format(device, batch_size, loss))\n",
    "\n",
    "tensorboard_model_path = create_unique_dir(\n",
    "    os.path.join(\".\", \"tensorboard-logs\", notebook_name, model_name)\n",
    ")\n",
    "loggers = [TensorBoardLogger(tensorboard_model_path)]\n",
    "print(\"logging at {}\".format(tensorboard_model_path))\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# First lines required for transfer learning from a sparse model in PyTorch\n",
    "#######################################################\n",
    "from neuralmagicML.pytorch.recal import (\n",
    "    ScheduledModifierManager,\n",
    "    ScheduledOptimizer,\n",
    "    ConstantKSModifier,\n",
    ")\n",
    "manager = ScheduledModifierManager([ConstantKSModifier(params=\"__ALL__\")])\n",
    "optim = ScheduledOptimizer(\n",
    "    optim,\n",
    "    model,\n",
    "    manager,\n",
    "    steps_per_epoch=math.ceil(len(train_dataset) / batch_size),\n",
    "    loggers=loggers,\n",
    ")\n",
    "print(\"created modifier, manager, and optimizer\")\n",
    "\n",
    "# we use prewritten trainers and testers to make the code more concise\n",
    "trainer = ModuleTrainer(model, device, loss, optim, loggers=loggers)\n",
    "tester = ModuleTester(model, device, loss, loggers=loggers)\n",
    "model = model.to(device)\n",
    "\n",
    "# startup tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tensorboard-logs\n",
    "\n",
    "# run initial validation for comparison\n",
    "tester.run_epoch(val_data_loader, epoch=-1, show_progress=False)\n",
    "\n",
    "#######################################################\n",
    "# Final lines required for recalibrating a model in PyTorch\n",
    "#######################################################\n",
    "num_epochs = 20\n",
    "for epoch in auto.tqdm(range(num_epochs), desc=\"transfer learning\"):\n",
    "    trainer.run_epoch(train_data_loader, epoch, show_progress=False)\n",
    "    tester.run_epoch(val_data_loader, epoch, show_progress=False)\n",
    "\n",
    "# delete so all modifiers are cleaned up before exporting\n",
    "del optim\n",
    "print(\"training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Exporting to ONNX\n",
    "\n",
    "Now that the model is fully recalibrated, you need to export it to an ONNX format, which is the format used by the Neural Magic Inference Engine. For PyTorch, exporting to ONNX is natively supported. In the cell block below a convenience class, `ModuleExporter()`, is used to handle exporting.\n",
    "\n",
    "Once the model is saved as an ONNX ﬁle, it is ready to be used for inference with Neural Magic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicML.utils import clean_path\n",
    "from neuralmagicML.pytorch.utils import ModuleExporter\n",
    "\n",
    "print(\"Exporting to onnx...\")\n",
    "export_path = clean_path(os.path.join(\".\", notebook_name, model_name))\n",
    "exporter = ModuleExporter(model, export_path)\n",
    "for batch in val_data_loader:\n",
    "    sample_input = batch[0]\n",
    "    break\n",
    "exporter.export_onnx(sample_input)\n",
    "print(\"Exported onnx to {}\".format(export_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "Run your model (ONNX file) through the Neural Magic Inference Engine. The following is an example of code that you can run in your Python console. Be sure to enter your ONNX file path and batch size.\n",
    "\n",
    "```\n",
    "from neuralmagic import create_model\n",
    "model = create_model(onnx_file_path=’some/path/to/model.onnx’, batch_size=1)\n",
    "inp = [numpy.random.rand(1, 3, 224, 224).astype(numpy.float32)]\n",
    "out = model.forward(inp)\n",
    "print(out)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
