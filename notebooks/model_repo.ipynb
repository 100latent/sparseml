{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading from Neural Magic's Model Repo\n",
    "\n",
    "Neural Networks can take a long time to train. Additionally, techniques like [model pruning](https://towardsdatascience.com/pruning-deep-neural-network-56cae1ec5505) and other optimizations sometimes take many trials and errors due to a large number of hyperparameters. However, it can often be necessary to do those model optimizations to achieve both your performance and optimizing goals. Luckily, though, pruned (sparsified) Neural Networks in the computer vision and natural language space [transfer learn](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a) very well. \n",
    "\n",
    "To make it easier to use pruned models, Neural Magic's ML team is actively creating pruned versions of popular models and datasets and updating the repo with them. Also, these models are tested thoroughly with the [Neural Magic Inference Engine](https://neuralmagic.com/) to ensure performance.\n",
    "\n",
    "This notebook provides a short and easy step by step walkthrough for downloading from the Neural Magic Model Repo. Below we will go through the following steps:\n",
    "1. Environment Setup\n",
    "2. Model Selection\n",
    "3. Model Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Below we try to add the project folder to the PYTHONPATH environment variable for our execution. If this does not work, we will need to install neuralmagicML into the system using `pip install ./` when you are located at the root of the folder.\n",
    "\n",
    "Additionally, please be sure to install from the requirements.txt file located at the root before running: `pip install -r ./requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_name = \"model_repo\"\n",
    "\n",
    "# environment setup for ease of use (puts neuralmagicML into the python package path)\n",
    "if \"WORKBOOK_DIR\" not in globals():\n",
    "    WORKBOOK_DIR = os.getcwd()\n",
    "\n",
    "package_path = os.path.abspath(\n",
    "    os.path.join(os.path.expanduser(WORKBOOK_DIR), os.pardir)\n",
    ")\n",
    "sys.path.extend([package_path])\n",
    "\n",
    "print(\"added {} to PYTHONPATH\".format(package_path))\n",
    "print(\"working out of {}\".format(WORKBOOK_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "There can be a lot of models available in repositories, so a simple UI is provided to make this selection process easier. Within the UI, filters can be applied for models trained in/on specific domains or datasets. Each network architecture listed out will also include options for the dataset it was trained on, ML frameworks (ONNX, PyTorch, TensorFlow, Keras), and the type. The type refers to how the models were trained and/or recalibrated. Specifically:\n",
    "- base - baseline model, trained generally as in the original paper\n",
    "- recal - a recalibrated model, it is recalibrated to the point of fully recovering the baseline model's metrics\n",
    "- recal-perf - a recalibrated model, it is recalibrated for performance to the point of recovering 99% of the baseline model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicML.nbutils import ModelSelectWidgetContainer\n",
    "\n",
    "print(\"creating ui...\")\n",
    "container = ModelSelectWidgetContainer()\n",
    "display(container.create())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Download\n",
    "\n",
    "After making a selection, run the cell block below to download the model locally. By default, it will save the model to a `model_repo` under the current working directory. The `save_path` can be changed as desired, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neuralmagicML.utils import clean_path\n",
    "\n",
    "model = container.selected_model\n",
    "save_onnx = container.selected_framework == \"onnx\"\n",
    "save_name = model.onnx_file_path if save_onnx else model.framework_file_path\n",
    "save_path = clean_path(os.path.join(\".\", notebook_name, save_name.replace(\"/\", \"-\")))\n",
    "\n",
    "print(\"downloading model to {}\".format(save_path))\n",
    "if save_onnx:\n",
    "    model.download_onnx_file(overwrite=True, overwrite_path=save_path)\n",
    "else:\n",
    "    model.download_framework_file(overwrite=True, overwrite_path=save_path)\n",
    "print(\"downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
